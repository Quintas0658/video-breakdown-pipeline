"""
AI Pipeline â€” ä» run_breakdown.py æå–çš„æ ¸å¿ƒé€»è¾‘
ä¾› FastAPI å’Œ CLI å…±ç”¨
"""

import os
import re
from pathlib import Path
from datetime import datetime
from typing import Generator

from dotenv import load_dotenv

# --------------- é…ç½® ---------------

PROJECT_DIR = Path(__file__).parent.parent.parent

# æŒ‰ä¼˜å…ˆçº§æŸ¥æ‰¾ .env æ–‡ä»¶
for env_path in [
    PROJECT_DIR / "web" / ".env",              # web/.env
    PROJECT_DIR / ".env",                      # é¡¹ç›®æ ¹ç›®å½•
    PROJECT_DIR / ".secrets" / ".env",         # é¡¹ç›®å†… .secrets/
    Path.home() / ".env",                      # ~/
]:
    if env_path.exists():
        load_dotenv(env_path, override=True)
        break

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")

OUTPUT_DIR = PROJECT_DIR / "output"
PERSONAS_DIR = PROJECT_DIR / "personas"

# æ¨¡å‹ä¼˜å…ˆçº§
STEP1_MODELS = [
    ("gemini", "gemini-2.5-pro"),
    ("openai", "gpt-4o"),
    ("anthropic", "claude-sonnet-4-20250514"),
]

STEP2_MODELS = [
    ("gemini", "gemini-2.5-pro"),
    ("anthropic", "claude-sonnet-4-20250514"),
    ("openai", "gpt-4o"),
]

# --------------- Prompt æ¨¡æ¿ ---------------

STEP1_PROMPT = """# Role
ä½ æ˜¯ä¸€ä¸ªæ·±åº¦ç†è§£ç›®æ ‡ç”¨æˆ·ç—›ç‚¹çš„å†…å®¹é¡¾é—®ã€‚ä½ çš„æ ¸å¿ƒèƒ½åŠ›æ˜¯ï¼šæŠŠä¸€ä¸ªè‹±æ–‡ä¸“ä¸šè§†é¢‘çš„å†…å®¹ï¼Œç¿»è¯‘æˆ"è¿™å’Œç”¨æˆ·æœ‰ä»€ä¹ˆå…³ç³»"ã€‚

# User Persona
{persona}

# Task
ä»¥ä¸‹æ˜¯ä¸€æœŸ YouTube è§†é¢‘çš„æ–‡å­—ç¨¿ï¼ˆè‹±æ–‡ï¼‰ã€‚è¯·åˆ†æï¼š

1. **ä¸€å¥è¯ä»·å€¼**ï¼šè¿™æœŸè§†é¢‘å¯¹ä¸Šè¿°ç”¨æˆ·ç”»åƒçš„æ ¸å¿ƒä»·å€¼æ˜¯ä»€ä¹ˆï¼Ÿï¼ˆç”¨ä¸€å¥ç›´å‡»å†…å¿ƒçš„è¯æ¦‚æ‹¬ï¼‰

2. **ç—›ç‚¹æ˜ å°„**ï¼ˆ3-5 ä¸ªï¼‰ï¼šç”¨æˆ·çš„å“ªäº›å…·ä½“ç—›ç‚¹å¯ä»¥è¢«è¿™æœŸè§†é¢‘è§£å†³ï¼Ÿ
   æ¯ä¸ªç—›ç‚¹è¯·åŒ…å«ï¼š
   - ç—›ç‚¹æè¿°ï¼ˆç”¨ç”¨æˆ·è‡ªå·±çš„è¯­è¨€ï¼Œæ¯”å¦‚"å†™å¥½å¼€å‘ä¿¡ä¸æ•¢å‘"ï¼‰
   - è®¤çŸ¥é‡æ„ï¼ˆç”¨æˆ·ç°åœ¨æ€ä¹ˆæƒ³ â†’ åº”è¯¥æ€ä¹ˆæƒ³ï¼‰
   - å¯¹åº”è§†é¢‘ä¸­çš„å“ªä¸ªæŠ€å·§/ç‰‡æ®µ

3. **æ·±å±‚ insight**ï¼šè¿™æœŸè§†é¢‘æœ‰ä»€ä¹ˆè¶…è¶Šå…·ä½“æŠ€å·§çš„ã€æ›´æ·±å±‚çš„æ´å¯Ÿï¼Ÿ
   ï¼ˆæ¯”å¦‚"çŠ¶æ€æ¯”è„šæœ¬é‡è¦"è¿™ç§è®¤çŸ¥å‡çº§ï¼‰

4. **æ˜å¤©è¡ŒåŠ¨**ï¼šç”¨æˆ·çœ‹å®Œåï¼Œæ˜å¤©æœ€è¯¥åšçš„ä¸€ä»¶äº‹æ˜¯ä»€ä¹ˆï¼Ÿ

# Video Transcript
{transcript}

# Output Requirements
- ç”¨ä¸­æ–‡å›ç­”
- è¯­æ°”åƒä¸€ä¸ªæœ‰ 5 å¹´ç»éªŒçš„åŒè¡Œåœ¨å’Œæ–°äººèŠå¤©ï¼Œä¸è¦åƒè€å¸ˆè®²è¯¾
- å…ˆè¯´ç”¨æˆ·çš„ç—›ï¼Œå†è¯´è§†é¢‘æ€ä¹ˆå¸®ä»–
- è¦å…·ä½“ã€è¦æœ‰ç”»é¢æ„Ÿï¼ˆ"å†™å¥½å¼€å‘ä¿¡é¼ æ ‡æ‚¬åœ¨å‘é€é”®ä¸Šä¸æ•¢ç‚¹"ï¼‰
- ä¸è¦åˆ— bullet point æ¸…å•ï¼Œè¦åƒåœ¨å’Œæœ‹å‹å¯¹è¯"""

STEP2_PROMPT = """# Role
ä½ æ˜¯ä¸€ä¸ªä¸“æ³¨äº"è§†é¢‘+ç¬”è®°"åŒè¯­å­¦ä¹ å†…å®¹çš„å†…å®¹ç­–åˆ’å¸ˆã€‚
ä½ çš„æ ¸å¿ƒèƒ½åŠ›æ˜¯ï¼šæŠŠè‹±æ–‡è§†é¢‘æ‹†è§£æˆè®©éæ¯è¯­ç”¨æˆ·"æ—¢å­¦åˆ°ä¸“ä¸šæŠ€èƒ½åˆæå‡è¯­è¨€èƒ½åŠ›"çš„ç»“æ„åŒ–å­¦ä¹ ææ–™ã€‚

# User Persona
{persona}

# Layer 0 Analysis (æ¥è‡ªä¸Šä¸€æ­¥çš„åˆ†æ)
ä»¥ä¸‹æ˜¯å¯¹è¿™æœŸè§†é¢‘å¯¹ç›®æ ‡ç”¨æˆ·ä»·å€¼çš„åˆ†æï¼Œè¯·åŸºäºæ­¤å±•å¼€æ·±åº¦æ‹†è§£ï¼š

{layer0}

# 4-Layer Analysis Framework

å¯¹äºè§†é¢‘ä¸­æ¯ä¸ªå’Œç”¨æˆ·ç—›ç‚¹ç›¸å…³çš„å…³é”®æŠ€å·§/ç‰‡æ®µï¼Œè¯·æŒ‰ä»¥ä¸‹ 4 å±‚åˆ†æã€‚
æ³¨æ„ï¼šè¾“å‡ºæ—¶ä¸è¦æ˜¾ç¤º "Layer 1/2/3/4" çš„æ ‡ç­¾ï¼Œè€Œæ˜¯è‡ªç„¶åœ°èå…¥å†…å®¹ã€‚

## Layer 1 â€” è¡¨è¾¾ï¼ˆSurfaceï¼‰
- å…³é”®è‹±æ–‡çŸ­è¯­ + ä¸­æ–‡ç¿»è¯‘
- è¯­æ„Ÿå’Œè¯­æ°”åŒºåˆ«ï¼ˆå¦‚ "folks" vs "people"ï¼Œ"over at" vs "from"ï¼‰
- å¸¸è§è¯¯ç”¨æˆ–æ··æ·†
- æ ‡æ³¨ç”¨æˆ·ç”»åƒå¯èƒ½ä¸è®¤è¯†çš„è¯/è¡¨è¾¾

## Layer 2 â€” ç­–ç•¥ï¼ˆWHYï¼‰
- è¿™ä¸ªæŠ€å·§èƒŒåçš„å¿ƒç†æœºåˆ¶ï¼ˆè§†é¢‘æœªå¿…è§£é‡Šäº†ï¼‰
- ä¸ºä»€ä¹ˆé€‰è¿™ä¸ªè¯´æ³•è€Œä¸æ˜¯å¦ä¸€ä¸ªï¼Ÿ
- æœ‰åå­—çš„æ¡†æ¶/æ–¹æ³•è®ºï¼ˆå¦‚ SPIN Selling, Sandlerï¼‰

## Layer 3 â€” ä¸Šä¸‹æ–‡ï¼ˆUnknown Unknownsï¼‰
- è§†é¢‘é»˜è®¤è§‚ä¼—çŸ¥é“ã€ä½†ç”¨æˆ·ç”»åƒå¯èƒ½ä¸çŸ¥é“çš„ä¸œè¥¿
- æ–‡åŒ–èƒŒæ™¯å·®å¼‚ï¼ˆå¦‚ç¾å›½ vs ä¸­å›½å•†åŠ¡ç¤¼ä»ªï¼‰
- è¡Œä¸šçŸ¥è¯†é»˜è®¤ï¼ˆæåˆ°çš„ä¹¦ã€æ¦‚å¿µã€äººç‰©ã€æœ¯è¯­ï¼‰
- è¿™ä¸ªæŠ€å·§åœ¨ä»€ä¹ˆæ–‡åŒ–/åœºæ™¯ä¸‹ work / ä¸ work

## Layer 4 â€” è¿ç§»åº”ç”¨
- ç”¨æˆ·ç”»åƒåœ¨è‡ªå·±çš„åœºæ™¯ä¸­æ€ä¹ˆç”¨ï¼Ÿ
- æä¾›å¡«ç©ºæ¨¡æ¿ï¼ˆfill-in-the-blankï¼‰
- æ ‡æ³¨ âœ… é€‚ç”¨åœºæ™¯ å’Œ âŒ ä¸é€‚ç”¨åœºæ™¯
- ç»™å‡ºå¯¹åº”çš„ email / WhatsApp / å±•ä¼šç‰ˆæœ¬

# Output Structure

è¯·æŒ‰ä»¥ä¸‹ç»“æ„è¾“å‡ºï¼š

## 1. å¼€å¤´ï¼šè¿™æœŸè§†é¢‘å’Œä½ æœ‰ä»€ä¹ˆå…³ç³»
ï¼ˆåŸºäº Layer 0ï¼Œç”¨ 2-3 æ®µå’Œç”¨æˆ·äº§ç”Ÿå…±é¸£ï¼‰

## 2. æŒ‰ç”¨æˆ·ç—›ç‚¹ç»„ç»‡çš„å†…å®¹ï¼ˆä¸æŒ‰è§†é¢‘æ—¶é—´çº¿ï¼‰
æ¯ä¸ªç—›ç‚¹åŒ…å«ï¼š
- **ä½ çš„ç°å®**ï¼šç—›ç‚¹æè¿°ï¼ˆæœ‰ç”»é¢æ„Ÿï¼‰
- **è®¤çŸ¥é‡æ„**ï¼šæ¢ä¸ªè§’åº¦ç†è§£
- **å…·ä½“åšæ³•**ï¼šè§†é¢‘æ•™çš„æ–¹æ³•ï¼ˆèåˆ 4 å±‚åˆ†æï¼‰
- **ä½ çš„ç‰ˆæœ¬**ï¼šå¡«ç©ºæ¨¡æ¿ / å³ç”¨è¯æœ¯

## 3. æ·±å±‚æ´å¯Ÿ
è¶…è¶ŠæŠ€å·§çš„è®¤çŸ¥å‡çº§

## 4. å³ç”¨å·¥å…·åŒ…
- ğŸ“‹ é€ŸæŸ¥å¡ï¼ˆä¸€é¡µçº¸ï¼Œæ‰€æœ‰å…³é”®è¯æœ¯ï¼Œç”¨ code block æ’ç‰ˆï¼‰
- âŒâœ… Mistake Mapï¼ˆå¸¸è§åšæ³• vs æ­£ç¡®åšæ³•è¡¨æ ¼ï¼‰
- âš¡ "æ˜å¤©å°±åš"ï¼ˆ1 ä¸ªå…·ä½“è¡ŒåŠ¨ï¼‰
- ğŸ“– å»¶ä¼¸é˜…è¯»ï¼ˆè§†é¢‘é»˜è®¤ä½ çŸ¥é“çš„ä¹¦/æ¦‚å¿µï¼‰

# Video Transcript
{transcript}

# Tone & Format
- ä¸­æ–‡ä¸ºä¸»ï¼Œè‹±æ–‡å…³é”®è¡¨è¾¾ä¿ç•™åŸæ–‡
- è¯­æ°”ï¼šæœ‰ç»éªŒçš„åŒè¡Œåˆ†äº«ï¼Œä¸æ˜¯æ•™ç§‘ä¹¦
- Markdown æ ¼å¼è¾“å‡º
- è¡¨æ ¼ç”¨äºå¯¹æ¯”ï¼Œcode block ç”¨äºæ¨¡æ¿/é€ŸæŸ¥å¡"""


# --------------- API è°ƒç”¨ ---------------

def call_gemini(messages: list, model: str, max_tokens: int = 16000) -> str:
    import requests

    if not GEMINI_API_KEY:
        raise RuntimeError("GEMINI_API_KEY æœªé…ç½®")

    contents = []
    system_instruction = None

    for msg in messages:
        role = msg["role"]
        if role == "system":
            system_instruction = msg["content"]
            continue
        if role == "assistant":
            role = "model"
        contents.append({"role": role, "parts": [{"text": msg["content"]}]})

    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={GEMINI_API_KEY}"

    payload = {
        "contents": contents,
        "generationConfig": {
            "maxOutputTokens": max_tokens,
        },
    }

    if system_instruction:
        payload["systemInstruction"] = {
            "parts": [{"text": system_instruction}]
        }

    response = requests.post(url, json=payload, timeout=600)

    if response.status_code != 200:
        error_info = response.json().get("error", {}).get("message", response.text)
        raise RuntimeError(f"Gemini {model}: {response.status_code} - {error_info}")

    data = response.json()
    return data["candidates"][0]["content"]["parts"][0]["text"]


def call_openai(messages: list, model: str, max_tokens: int = 16000) -> str:
    from openai import OpenAI

    if not OPENAI_API_KEY:
        raise RuntimeError("OPENAI_API_KEY æœªé…ç½®")

    client = OpenAI(api_key=OPENAI_API_KEY)
    response = client.chat.completions.create(
        model=model,
        messages=messages,
        max_tokens=max_tokens,
    )
    return response.choices[0].message.content


def call_anthropic(messages: list, model: str, max_tokens: int = 16000) -> str:
    import requests

    if not ANTHROPIC_API_KEY:
        raise RuntimeError("ANTHROPIC_API_KEY æœªé…ç½®")

    system_content = ""
    api_messages = []
    for msg in messages:
        if msg["role"] == "system":
            system_content = msg["content"]
        else:
            api_messages.append(msg)

    headers = {
        "x-api-key": ANTHROPIC_API_KEY,
        "anthropic-version": "2023-06-01",
        "content-type": "application/json",
    }

    payload = {
        "model": model,
        "max_tokens": max_tokens,
        "messages": api_messages,
    }
    if system_content:
        payload["system"] = system_content

    response = requests.post(
        "https://api.anthropic.com/v1/messages",
        headers=headers,
        json=payload,
        timeout=600,
    )

    if response.status_code != 200:
        raise RuntimeError(f"Claude {model}: {response.status_code} - {response.text[:200]}")

    data = response.json()
    return data["content"][0]["text"]


PROVIDER_CALLERS = {
    "gemini": call_gemini,
    "openai": call_openai,
    "anthropic": call_anthropic,
}


def call_with_fallback(messages: list, model_priority: list, step_name: str) -> tuple[str, str]:
    errors = []
    for provider, model in model_priority:
        try:
            caller = PROVIDER_CALLERS[provider]
            content = caller(messages, model)
            return content, f"{provider}/{model}"
        except Exception as e:
            error_msg = str(e)[:150]
            errors.append(f"{provider}/{model}: {error_msg}")

    raise RuntimeError(
        f"[{step_name}] æ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥:\n" + "\n".join(f"  - {e}" for e in errors)
    )


# --------------- Pipeline ---------------

def load_persona(persona_name: str, personas_dir: Path = None) -> str:
    if personas_dir is None:
        personas_dir = PERSONAS_DIR

    persona_path = Path(persona_name)
    if persona_path.exists():
        return persona_path.read_text(encoding="utf-8")

    for ext in ["", ".md", ".txt"]:
        p = personas_dir / f"{persona_name}{ext}"
        if p.exists():
            return p.read_text(encoding="utf-8")

    return persona_name


def list_personas(personas_dir: Path = None) -> list[dict]:
    if personas_dir is None:
        personas_dir = PERSONAS_DIR

    personas = []
    if not personas_dir.exists():
        return personas

    for f in sorted(personas_dir.iterdir()):
        if f.suffix in (".md", ".txt"):
            personas.append({
                "name": f.stem,
                "filename": f.name,
                "content": f.read_text(encoding="utf-8"),
            })
    return personas


def run_step1(transcript: str, persona: str) -> tuple[str, str]:
    prompt = STEP1_PROMPT.format(persona=persona, transcript=transcript)
    messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ·±åº¦ç†è§£ç”¨æˆ·ç—›ç‚¹çš„å†…å®¹é¡¾é—®ã€‚"},
        {"role": "user", "content": prompt},
    ]
    return call_with_fallback(messages, STEP1_MODELS, "Step 1: Layer 0")


def run_step2(transcript: str, persona: str, layer0: str) -> tuple[str, str]:
    prompt = STEP2_PROMPT.format(
        persona=persona,
        layer0=layer0,
        transcript=transcript,
    )
    messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“æ³¨äºåŒè¯­è§†é¢‘å­¦ä¹ å†…å®¹çš„ç­–åˆ’å¸ˆã€‚"},
        {"role": "user", "content": prompt},
    ]
    return call_with_fallback(messages, STEP2_MODELS, "Step 2: Breakdown")


def run_pipeline_streaming(transcript: str, persona_name: str = "å¤–è´¸å°ç™½") -> Generator[dict, None, None]:
    """æµå¼ pipelineï¼Œyield SSE äº‹ä»¶"""
    persona = load_persona(persona_name)

    yield {"event": "progress", "data": "æ­£åœ¨è¿›è¡Œ Layer 0 ä»·å€¼åˆ†æ..."}

    try:
        layer0, model1 = run_step1(transcript, persona)
        yield {
            "event": "layer0",
            "data": {"content": layer0, "model": model1},
        }
    except Exception as e:
        yield {"event": "error", "data": f"Layer 0 åˆ†æå¤±è´¥: {str(e)[:200]}"}
        return

    yield {"event": "progress", "data": "æ­£åœ¨è¿›è¡Œ 4 å±‚æ·±åº¦æ‹†è§£..."}

    try:
        breakdown, model2 = run_step2(transcript, persona, layer0)
        yield {
            "event": "breakdown",
            "data": {"content": breakdown, "model": model2},
        }
    except Exception as e:
        yield {"event": "error", "data": f"4 å±‚æ‹†è§£å¤±è´¥: {str(e)[:200]}"}
        return

    # ä¿å­˜åˆ°æ–‡ä»¶
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    safe_persona = re.sub(r'[^\w\-]', '_', persona_name)

    breakdown_path = OUTPUT_DIR / f"{timestamp}_{safe_persona}_breakdown.md"
    breakdown_path.write_text(
        f"# è§†é¢‘æ‹†è§£\n\n"
        f"> Step 1 æ¨¡å‹: {model1}\n"
        f"> Step 2 æ¨¡å‹: {model2}\n"
        f"> ç”»åƒ: {persona_name}\n"
        f"> æ—¶é—´: {datetime.now().isoformat()}\n\n"
        f"---\n\n{breakdown}",
        encoding="utf-8",
    )

    yield {"event": "done", "data": str(breakdown_path)}


# --------------- ToC ç›®å½•ç”Ÿæˆ ---------------

import json

TOC_PROMPT = """You are a content analyst. Given the following video transcript with timestamps, identify the major topic sections/chapters.

For each chapter, provide:
- "title": A concise, descriptive title in the SAME LANGUAGE as the transcript
- "start_time": The approximate start time in seconds
- "summary": A one-sentence summary of what this section covers, in the SAME LANGUAGE as the transcript

Return ONLY a JSON array, no other text. Example:
[
  {{"title": "Introduction and Why Outbound Matters", "start_time": 0, "summary": "The speaker introduces himself and explains why outbound is essential for hitting quota."}},
  {{"title": "Cold Email Strategy That Gets Replies", "start_time": 245, "summary": "How to write cold emails with high reply rates using buyer-centric messaging."}}
]

Guidelines:
- Typically 5-10 chapters for a 10-30 minute video
- Each chapter should represent a meaningful topic shift
- Titles should be specific and descriptive, not generic like "Part 1"
- start_time should be in seconds (integer)
- Keep the title and summary in the same language as the video transcript

## Transcript (with timestamps in [MM:SS] format):
{transcript}"""

TOC_MODELS = [
    ("gemini", "gemini-2.5-flash"),
    ("openai", "gpt-4o-mini"),
    ("anthropic", "claude-sonnet-4-20250514"),
]


def generate_toc(transcript_with_timestamps: str) -> list[dict]:
    """
    ç”¨ AI ç”Ÿæˆè§†é¢‘ç« èŠ‚ç›®å½•

    transcript_with_timestamps: å¸¦æ—¶é—´æˆ³çš„å®Œæ•´æ–‡æœ¬ï¼Œæ ¼å¼å¦‚ "[0:00] text [0:30] text ..."
    è¿”å›: [{"title", "title_zh", "start_time", "summary"}]
    """
    prompt = TOC_PROMPT.format(transcript=transcript_with_timestamps)
    messages = [
        {"role": "system", "content": "You are a content analyst that outputs only valid JSON."},
        {"role": "user", "content": prompt},
    ]

    content, model = call_with_fallback(messages, TOC_MODELS, "ToC Generation")

    # è§£æ JSON â€” å¤„ç†å¯èƒ½çš„ markdown ä»£ç å—åŒ…è£¹
    content = content.strip()
    if content.startswith("```"):
        # å»æ‰ ```json ... ```
        content = re.sub(r'^```\w*\n?', '', content)
        content = re.sub(r'\n?```$', '', content)
        content = content.strip()

    chapters = json.loads(content)

    # ç¡®ä¿ start_time æ˜¯æ•´æ•°
    for ch in chapters:
        ch["start_time"] = int(ch.get("start_time", 0))

    return chapters


# --------------- Context Notes ç”Ÿæˆ ---------------

CONTEXT_NOTES_PROMPT = """You are a cultural and language context analyst helping Chinese-speaking learners understand video content at a deeper level.

Given a video transcript with numbered segments, identify moments where non-native speakers would benefit from additional context. Look for:

1. **Cultural References**: Idioms, slang, cultural assumptions, humor, sarcasm, pop-culture references
2. **Knowledge Background**: Industry jargon, frameworks, referenced people/books/concepts, unstated assumptions the speaker expects the audience to know
3. **Social Connotation**: Tone shifts, sarcasm detection, implied attitudes, social implications that a non-native speaker would miss (e.g., "Nice job" said sarcastically)
4. **Dialect Warning**: Regional dialect or accent-specific usage that could confuse learners (e.g., UK vs US English, Mexican vs Spain Spanish)

For each segment that needs a note, provide:
- "segment_index": The segment number (0-based integer)
- "type": "cultural", "knowledge", "social_connotation", or "dialect_warning"
- "title": A short label in the SAME language as the transcript (e.g., English title for English video)
- "note": A concise explanation in Chinese (1-2 sentences, written for a Chinese learner)

Return ONLY a valid JSON array, no other text:
[
  {{"segment_index": 3, "type": "cultural", "title": "Chomping at the bit", "note": "è¿™æ˜¯ä¸€ä¸ªè‹±è¯­ä¹ è¯­ï¼ŒåŸæ„æ˜¯é©¬æ€¥ç€å’¬åš¼å­æƒ³è·‘ï¼Œå¼•ç”³ä¸º'è¿«ä¸åŠå¾…'ã€‚"}},
  {{"segment_index": 7, "type": "knowledge", "title": "SPIN Selling", "note": "SPIN Selling æ˜¯ Neil Rackham æå‡ºçš„å’¨è¯¢å¼é”€å”®æ¡†æ¶ï¼Œé€šè¿‡æé—®å‘ç°å®¢æˆ·éœ€æ±‚ã€‚"}},
  {{"segment_index": 12, "type": "social_connotation", "title": "Sarcastic 'Great job'", "note": "è¯´è¯äººè¯­æ°”å¸¦æœ‰è®½åˆºï¼Œå®é™…æ„æ€æ˜¯åšå¾—å¾ˆå·®ã€‚æ³¨æ„è¯­è°ƒå’Œä¸Šä¸‹æ–‡ã€‚"}},
  {{"segment_index": 15, "type": "dialect_warning", "title": "Reckon (UK)", "note": "'reckon' åœ¨è‹±å¼è‹±è¯­ä¸­å¾ˆå¸¸è§ï¼Œæ„ä¸º'è®¤ä¸º/è§‰å¾—'ï¼Œä½†åœ¨ç¾å¼è‹±è¯­ä¸­è¾ƒå°‘ä½¿ç”¨ã€‚"}}
]

Guidelines:
- Focus on things a Chinese native speaker would likely miss or misunderstand
- Don't annotate simple vocabulary â€” focus on cultural context and background knowledge
- Aim for 8-15 notes per 10-minute video (be selective, not exhaustive)
- Keep notes concise and actionable

## Transcript (numbered segments):
{transcript_with_indices}"""

CONTEXT_NOTES_MODELS = [
    ("gemini", "gemini-2.5-flash"),
    ("openai", "gpt-4o-mini"),
    ("anthropic", "claude-sonnet-4-20250514"),
]


def generate_context_notes(transcript_with_indices: str) -> list[dict]:
    """
    ç”¨ AI ç”Ÿæˆä¸Šä¸‹æ–‡æ³¨é‡Š

    transcript_with_indices: å¸¦åºå·çš„æ–‡æœ¬ï¼Œæ ¼å¼å¦‚ "[0] text\n[1] text\n..."
    è¿”å›: [{"segment_index", "type", "title", "note"}]
    """
    prompt = CONTEXT_NOTES_PROMPT.format(transcript_with_indices=transcript_with_indices)
    messages = [
        {"role": "system", "content": "You are a context analyst. Output only valid JSON."},
        {"role": "user", "content": prompt},
    ]

    content, model = call_with_fallback(messages, CONTEXT_NOTES_MODELS, "Context Notes")

    # è§£æ JSON
    content = content.strip()
    if content.startswith("```"):
        content = re.sub(r'^```\w*\n?', '', content)
        content = re.sub(r'\n?```$', '', content)
        content = content.strip()

    try:
        notes = json.loads(content)
    except json.JSONDecodeError as e:
        print(f"Context notes JSON parsing failed: {str(e)[:100]}, attempting repair...")
        notes = None

        # ç­–ç•¥ 1: æˆªæ–­åˆ°æœ€åä¸€ä¸ªå®Œæ•´å¯¹è±¡ }
        last_brace = content.rfind('}')
        if last_brace > 0:
            candidate = content[:last_brace+1].rstrip().rstrip(',') + ']'
            arr_start = candidate.find('[')
            if arr_start >= 0:
                candidate = candidate[arr_start:]
            try:
                notes = json.loads(candidate)
                print(f"Context notes JSON repaired, got {len(notes)} notes")
            except json.JSONDecodeError:
                pass

        # ç­–ç•¥ 2: å°¾éƒ¨æ‹¬å·ä¿®å¤
        if notes is None:
            fixed = content.rstrip().rstrip(',')
            if not fixed.endswith(']'):
                fixed += ']'
            try:
                notes = json.loads(fixed)
                print(f"Context notes JSON repaired (bracket fix), got {len(notes)} notes")
            except json.JSONDecodeError:
                raise ValueError(f"Cannot repair context notes JSON: {str(e)[:200]}")

    # ç¡®ä¿ segment_index æ˜¯æ•´æ•°
    for note in notes:
        note["segment_index"] = int(note.get("segment_index", 0))

    return notes


# --------------- AI è¯æ±‡é«˜äº® ---------------

HIGHLIGHTS_PROMPT = """You are an expert language coach specializing in register-aware expression detection for Chinese-speaking professionals learning from authentic video content.

Your job: Identify expressions in the transcript that are valuable for learners, and classify each by its REGISTER (how/where it's used), not just its form.

## Register Tag System (4 tags)

ğŸŸ¢ **general_spoken** â€” Usable in any casual or semi-formal conversation. Natural and versatile.
   Examples: "figure out", "kind of", "no worries", "makes sense"

ğŸ”µ **professional_spoken** â€” Native speakers use this in meetings, presentations, and professional settings. THE HIGH-VALUE TARGET ZONE for career-focused learners.
   Examples: "aligned with", "circle back", "drill down", "leverage", "move the needle", "stakeholder buy-in"

ğŸŸ¡ **regional_cultural** â€” Specific to a country, region, or culture. MUST include a context note explaining which region.
   Examples: "mate" (UK/AU), "reckon" (UK informal), "touch wood" (UK) vs "knock on wood" (US)

âšª **formal_written** â€” Grammatically correct but sounds stilted/unnatural in speech. Flag so learners know NOT to overuse it verbally.
   Examples: "I concur", "henceforth", "utilize" (when "use" works fine), "aforementioned"

KEY PRINCIPLE: Register must follow the VIDEO'S actual context, not a preset template. A tech review and a business meeting call for different register profiles.

## 3-Layer Detection

For each expression, provide:
- "segment_index": The number shown in [brackets] before the segment text. Return this EXACT number.
- "phrase": EXACT text as it appears in the transcript (for string matching)
- "register": "general_spoken" | "professional_spoken" | "regional_cultural" | "formal_written"
- "level": CEFR difficulty ("A2", "B1", "B2", or "C1")
- "frequency": Estimated spoken frequency ("very_high" | "high" | "medium" | "low")
- "translation": Chinese translation + usage note (1 sentence)
- "alternative": What a basic learner would say instead (null if not applicable)

Return ONLY a valid JSON array:
[
  {{"segment_index": 2, "phrase": "aligned with", "register": "professional_spoken", "level": "B2", "frequency": "high", "translation": "ä¸...ä¸€è‡´/ä¿æŒåŒæ­¥ã€‚æ¯” agree with æ›´èŒä¸šåŒ–ï¼Œå¸¸ç”¨äºä¼šè®®å’Œé‚®ä»¶", "alternative": "agree with"}},
  {{"segment_index": 5, "phrase": "circle back", "register": "professional_spoken", "level": "B2", "frequency": "high", "translation": "ç¨åå†è®¨è®º/å›å¤´å†è¯´ã€‚èŒåœºé«˜é¢‘ç”¨è¯­ï¼Œå°¤å…¶åœ¨ä¼šè®®ä¸­æš‚æ—¶æç½®è¯é¢˜æ—¶", "alternative": "discuss later"}},
  {{"segment_index": 8, "phrase": "utilize", "register": "formal_written", "level": "B2", "frequency": "low", "translation": "ä½¿ç”¨ã€‚è¿‡äºæ­£å¼ï¼Œå£è¯­ä¸­ç›´æ¥è¯´ use æ›´è‡ªç„¶", "alternative": "use"}}
]

CRITICAL JSON FORMATTING RULES:
- Your response MUST be a complete, valid JSON array
- Escape all double quotes inside string values using backslash: \"
- Do NOT use line breaks or special characters inside string values
- Ensure all string values are properly closed with quotes
- The last item must NOT have a trailing comma

Guidelines:
- Be THOROUGH: scan EVERY segment from start to end. Extract ALL expressions that match the criteria â€” no quantity limit. Do NOT stop early or skip later segments.
- The phrase must appear EXACTLY in the segment text (will be used for string matching).
- Don't highlight basic A1 vocabulary ("meeting", "email", "good").
- DO highlight phrases that a Chinese professional with CET-6 would recognize but wouldn't naturally USE.
- Phrasal verbs are especially valuable â€” even advanced learners underuse them.
- For formal_written register, emphasize that the expression is NOT recommended for speaking.
- For regional_cultural register, ALWAYS explain which region in the translation.
- Frequency should reflect how often native speakers use this in SPOKEN contexts (not written).

## Transcript (numbered segments):
{transcript_with_indices}"""

HIGHLIGHTS_MODELS = [
    ("gemini", "gemini-2.5-flash"),
    ("openai", "gpt-4o-mini"),
    ("anthropic", "claude-sonnet-4-20250514"),
]


def generate_highlights(transcript_with_indices: str) -> list[dict]:
    """
    ç”¨ AI ç”Ÿæˆè¯æ±‡é«˜äº®

    transcript_with_indices: å¸¦åºå·çš„æ–‡æœ¬ï¼Œæ ¼å¼å¦‚ "[0] text\n[1] text\n..."
    è¿”å›: [{"segment_index", "phrase", "category", "translation", "level", "alternative"}]
    """
    prompt = HIGHLIGHTS_PROMPT.format(transcript_with_indices=transcript_with_indices)
    messages = [
        {"role": "system", "content": "You are a vocabulary analyst for language learners. Output only valid JSON."},
        {"role": "user", "content": prompt},
    ]

    content, model = call_with_fallback(messages, HIGHLIGHTS_MODELS, "AI Highlights")

    # è§£æ JSON
    content = content.strip()
    if content.startswith("```"):
        content = re.sub(r'^```\w*\n?', '', content)
        content = re.sub(r'\n?```$', '', content)
        content = content.strip()

    # å°è¯•è§£æ JSONï¼Œå¤±è´¥åˆ™å°è¯•ä¿®å¤
    try:
        highlights = json.loads(content)
    except json.JSONDecodeError as e:
        print(f"JSON parsing failed: {str(e)[:100]}, attempting repair...")
        highlights = None

        # ç­–ç•¥ 1: æ‰¾åˆ°æœ€åä¸€ä¸ªå®Œæ•´å¯¹è±¡ }ï¼Œæˆªæ–­å¹¶è¡¥ ]
        last_brace = content.rfind('}')
        if last_brace > 0:
            candidate = content[:last_brace+1].rstrip().rstrip(',') + ']'
            arr_start = candidate.find('[')
            if arr_start >= 0:
                candidate = candidate[arr_start:]
            try:
                highlights = json.loads(candidate)
                print(f"JSON repaired (truncate to last complete object), got {len(highlights)} highlights")
            except json.JSONDecodeError:
                pass

        # ç­–ç•¥ 2: å»æ‰å°¾é€—å· + æ‰¾æœ€åçš„ ]
        if highlights is None:
            fixed = content.rstrip().rstrip(',')
            last_bracket = fixed.rfind(']')
            if last_bracket > 0:
                fixed = fixed[:last_bracket+1]
            try:
                highlights = json.loads(fixed)
                print(f"JSON repaired (trailing bracket), got {len(highlights)} highlights")
            except json.JSONDecodeError:
                pass

        if highlights is None:
            raise ValueError(f"JSON repair failed for highlights: {str(e)[:100]}")

    # ç¡®ä¿ segment_index æ˜¯æ•´æ•°
    for h in highlights:
        h["segment_index"] = int(h.get("segment_index", 0))

    return highlights
